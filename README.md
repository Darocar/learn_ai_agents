# LEARN-AI-AGENTS ‚Äî Branch `02_adding_streamlit_ui_v2`

This branch adds **Streamlit UI** and **Discovery System** for interactive exploration of the AI agents.

**What's new in this branch:**
- ‚úÖ **Streamlit Web UI**: Interactive chat interface with use case selection
- ‚úÖ **Discovery System**: Complete hexagonal implementation for system introspection
  - List all components (LLMs, databases, etc.)
  - List all agents with their dependencies
  - List all use cases with routing information
- ‚úÖ **VS Code Launch Configurations**: Debug both FastAPI and Streamlit
- ‚úÖ **Monorepo Structure**: Workspace with multiple packages (`learn_ai_agents`, `streamlit_ui`)

> Stack: **Python 3.12** + **uv** + **FastAPI** + **LangChain** + **Groq** + **Streamlit**

---

## üéØ What This Branch Demonstrates

### New Features

#### 1. Discovery System (Hexagonal Implementation)
Complete implementation following the architecture:
- **Domain Models**: `Component`, `Agent`, `UseCase` entities
- **Service**: `SettingsResourceDiscovery` reads configuration
- **Use Case**: `DiscoveryUseCase` orchestrates discovery operations
- **API Endpoints**: `/discover/components`, `/discover/agents`, `/discover/use-cases`, `/discover/all`
- **Purpose**: Runtime introspection of the system configuration

#### 2. Streamlit UI
Web interface for interacting with agents:
- **Home Page**: System overview with discovery information
- **Chat Page**: 
  - Dynamic use case selection from discovery API
  - Real-time agent information display
  - Invoke and Stream modes
  - Conversation management (ID tracking, clear/reset)
- **Responsive Design**: Clean, minimal interface

#### 3. Development Tools
- **Launch Configurations**: `.vscode/launch.json` for debugging
  - `Run learn_ai_agents`: Debug FastAPI application
  - `Run streamlit`: Debug Streamlit UI
- **Environment Setup**: Separate `.env` files for each package

---

## üöÄ Quick Start

```bash
# 1. Sync all workspace dependencies
uv sync

# 2. Set up environment variables
# For learn_ai_agents
cp .env.example .env
# Add GROQ_API_KEY to .env

# For streamlit_ui
cp src/streamlit_ui/.env.example src/streamlit_ui/.env
# Configure AGENTS_API_BASE_URL (default: http://127.0.0.1:8000)

# 3. Run FastAPI backend
cd src/learn_ai_agents
python -m learn_ai_agents

# 4. Run Streamlit UI (in another terminal)
cd src/streamlit_ui
streamlit run streamlit_ui/Home_Page.py
```

**Or use VS Code debugger:**
- Press F5 and select "Run learn_ai_agents" or "Run streamlit"

---

## üìÅ Files Added in This Branch

### Discovery System
```
domain/models/agents/
‚îî‚îÄ‚îÄ discovery.py                           # Component, Agent, UseCase models

application/
‚îú‚îÄ‚îÄ dtos/discovery/
‚îÇ   ‚îî‚îÄ‚îÄ discovery.py                       # Discovery DTOs
‚îî‚îÄ‚îÄ use_cases/discovery/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ use_case.py                        # DiscoveryUseCase

domain/services/agents/
‚îî‚îÄ‚îÄ settings_resource_discovery.py        # SettingsResourceDiscovery service

infrastructure/inbound/controllers/discovery/
‚îú‚îÄ‚îÄ __init__.py
‚îî‚îÄ‚îÄ discovery.py                           # Discovery API router
```

### Streamlit UI
```
src/streamlit_ui/
‚îú‚îÄ‚îÄ .env.example                           # Environment template
‚îú‚îÄ‚îÄ pyproject.toml                         # Streamlit dependencies
‚îú‚îÄ‚îÄ README.md                              # UI-specific documentation
‚îî‚îÄ‚îÄ streamlit_ui/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ Home_Page.py                       # Landing page
    ‚îú‚îÄ‚îÄ pages/
    ‚îÇ   ‚îú‚îÄ‚îÄ 1_Chat.py                      # Chat interface
    ‚îÇ   ‚îú‚îÄ‚îÄ 2_Conversation_History.py      # (MongoDB-based, disabled for now)
    ‚îÇ   ‚îî‚îÄ‚îÄ 3_Character_Chat.py            # (MongoDB-based, disabled for now)
    ‚îî‚îÄ‚îÄ utils/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îî‚îÄ‚îÄ mongo_client.py                # MongoDB utilities (for future use)
```

### Configuration & Tools
```
.vscode/
‚îî‚îÄ‚îÄ launch.json                            # VS Code debug configurations

pyproject.toml                             # Updated with streamlit_ui workspace member
```

---

## üîÑ Request Flow

### Discovery Flow
```
GET /discover/use-cases 
  ‚Üí DiscoveryUseCase.discover_use_cases() 
  ‚Üí SettingsResourceDiscovery.list_use_cases()
  ‚Üí Returns UseCasesResponseDTO
```

### Chat Flow
```
Streamlit UI ‚Üí GET /discover/use-cases ‚Üí Display use case selector
User selects use case + types message
Streamlit UI ‚Üí POST /{use_case_path}/invoke ‚Üí BasicAnswerUseCase ‚Üí Agent ‚Üí LLM ‚Üí Response
```

---

## Hexagonal Architecture Overview

```
domain/             # Pure business logic (no frameworks)
‚îú‚îÄ‚îÄ models/         # Entities & value objects
‚îî‚îÄ‚îÄ services/       # Domain policies

application/        # Use case orchestration
‚îú‚îÄ‚îÄ dtos/           # Input/output data structures
‚îú‚îÄ‚îÄ inbound_ports/  # Interfaces exposed to controllers
‚îú‚îÄ‚îÄ outbound_ports/ # Interfaces for external dependencies
‚îî‚îÄ‚îÄ use_cases/      # Business workflows

infrastructure/     # Framework & vendor code
‚îú‚îÄ‚îÄ inbound/        # Controllers (FastAPI)
‚îú‚îÄ‚îÄ outbound/       # Adapters (LLM, DB, etc.)
‚îî‚îÄ‚îÄ bootstrap/      # Dependency injection
```

See [src/learn_ai_agents/README.md](src/learn_ai_agents/README.md) for detailed code documentation.

---

## Development Commands

```bash
# Install dependencies
uv sync

# Code quality
make format     # Auto-fix formatting
make lint       # Check code quality
make type-check # Run mypy
make verify     # Run all checks

# Run application (when complete)
python -m learn_ai_agents
```

---

## Full Repository Structure

```
.
‚îú‚îÄ‚îÄ data/                       # Sample corpora, fixtures, small test assets (NOT large datasets)
‚îú‚îÄ‚îÄ notebooks/                  # Exploration / spike notebooks (kept out of the src/ code)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ learn_ai_agents/
‚îÇ       ‚îú‚îÄ‚îÄ application/        # The "use-cases" circle: ports + orchestrators (no vendor code)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dtos/           # Input/Output DTOs for use cases (transport-agnostic shapes)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ inbound_ports/  # Interfaces the app exposes (controllers call these)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ outbound_ports/ # Interfaces the app needs (LLM, vector, repos, tracing, tools)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ use_cases/      # Application services (implement inbound ports; orchestrate domain)
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ domain/             # Pure business language: entities, value objects, domain services
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ models/         # Conversation, Message, ToolCall, etc.
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ services/       # Policies & domain services (no I/O, no framework types)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py   # Domain-specific error types
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ utils.py        # Tiny, pure helpers shared across domain code
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ infrastructure/     # Adapters & glue (edge of the hexagon)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ inbound/        # Drivers (e.g., FastAPI routers) that CALL inbound ports
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ outbound/       # Tech adapters that IMPLEMENT outbound ports
‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ llm/        # LLM adapters (LangChain/PydanticAI/OpenAI/Groq‚Ä¶)
‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ persistence/# Conversation/history stores, vector DBs, caches
‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ tools/      # Concrete tool adapters (S3, HTTP APIs, calendars, etc.)
‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ tracers/    # Observability/telemetry adapters (Phoenix, Opik‚Ä¶)
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ bootstrap/          # Composition root: build adapters, inject into use cases
‚îÇ       ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ static/                     # Diagrams, sample JSONs for docs, etc. (served/read-only)
‚îú‚îÄ‚îÄ tests/                      # unit/, integration/, e2e/ (TDD-friendly from day one)
‚îÇ
‚îú‚îÄ‚îÄ .env.example                # Env var template (copy to .env locally; never commit secrets)
‚îú‚îÄ‚îÄ .dockerignore
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .pre-commit-config.yaml     # Linters/formatters/hooks (e.g., Ruff, mypy) wired via pre-commit
‚îú‚îÄ‚îÄ Dockerfile                  # Image with Python 3.12 + uv
‚îú‚îÄ‚îÄ docker-compose.yaml         # Local stack orchestration (API + optional backing services)
‚îú‚îÄ‚îÄ Makefile                    # One-liners: `make setup`, `make test`, `make run`, etc.
‚îú‚îÄ‚îÄ pyproject.toml              # Project metadata & deps (PEP 621); uv reads this
‚îî‚îÄ‚îÄ README.md                   # You‚Äôre here
```

### Layer responsibilities (at a glance)

- **application/** ‚Äî Use‚Äëcase layer (a.k.a. ‚Äúapplication services‚Äù). Contains:
  - **inbound_ports/**: *input boundaries* (interfaces) that controllers call.
  - **use_cases/**: classes that **implement inbound ports** and orchestrate domain + outbound ports.
  - **outbound_ports/**: the app‚Äôs needs (LLM, vector index, repositories, observability, tools) expressed as interfaces.
  - **dtos/**: input/output data shapes used by use cases (keeps HTTP models out of the core).
- **domain/** ‚Äî Pure business concepts: entities/value objects (`models/`) and policies (`services/`). Absolutely no vendor or framework imports.
- **infrastructure/** ‚Äî Adapters on the edge:
  - **inbound/**: FastAPI routers/controllers (they validate, map DTOs, then **call inbound ports**).
  - **outbound/**: concrete tech adapters that **implement outbound ports** (LLM providers, DBs, tracers, tools).
- **bootstrap/** ‚Äî The **Composition Root**. Instantiate adapters and inject them into use cases (constructor injection). Only this layer knows which vendor you chose. The rest of the app stays agnostic.

---

## How a request flows (end‚Äëto‚Äëend)

1. **FastAPI router** (`infrastructure/inbound/`) receives HTTP, validates input models, and maps them to **application DTOs**.  
2. Router **calls an inbound port** (`application/inbound_ports/`).  
3. The **use case** (`application/use_cases/`) implements that port: loads domain state, applies policies, and calls **outbound ports** for I/O.  
4. **Outbound adapters** (`infrastructure/outbound/`) talk to real tech (LLM, DB, tracer, tools) and return domain‚Äëfriendly results.  
5. The use case returns a result DTO; the router maps it to an HTTP response model.

This keeps controllers thin and the core independent of frameworks/providers.

---

## Python 3.12 + uv quickstart

> Requires: [uv](https://docs.astral.sh/uv/) installed and available on your PATH.

```bash
# 1) Ensure Python 3.12 is installed via uv
uv python install 3.12

# 2) Create & sync the project environment from pyproject.toml
uv sync

# 3) (Later) run the API once the first route exists
uv run uvicorn learn_ai_agents.<your_api_module>:app --reload
```

**Notes**
- `pyproject.toml` follows **PEP 621** so tools (including uv) can read project metadata & dependencies.
- `uv sync` creates an isolated `.venv/` and keeps it in sync with the `pyproject.toml`.
- `Makefile` provides convenient shortcuts once targets are added.

---

## Prerequisites & External Dependencies

This project integrates with several external services and tools. Here's what you need to set up:

### ü§ñ Groq (LLM Provider)

**What it is**: Cloud-based LLM inference platform providing fast access to open models like Llama 3.3.

**Setup**:
1. Create an account at [https://console.groq.com](https://console.groq.com)
2. Navigate to API Keys section
3. Generate a new API key
4. Add to your `.env` file:
   ```bash
   GROQ_API_KEY=your_groq_api_key_here
   ```

**Why we use it**: Groq provides fast, cost-effective access to state-of-the-art open-source LLMs with OpenAI-compatible API.

### üî≠ Opik (Observability & Tracing)

**What it is**: Agent observability platform for tracing LLM calls, tool executions, and conversation flows.

**Setup**:
1. Create an account at [https://www.comet.com/opik](https://www.comet.com/opik)
2. Create a new workspace for your project
3. Go to Settings ‚Üí API Keys
4. Generate an API key
5. Add to your `.env` file:
   ```bash
   OPIK_API_KEY=your_opik_api_key_here
   OPIK_WORKSPACE=your_workspace_name
   ```

**Why we use it**: Opik provides deep visibility into agent execution, helping debug issues and optimize performance.

**Note**: Available from Branch 06 onwards.

### üê≥ MongoDB (Conversation Persistence)

**What it is**: NoSQL database for storing conversation history and checkpoints.

**Setup**:
1. **Install Docker**: Ensure Docker is installed on your system
   - [Docker Desktop](https://www.docker.com/products/docker-desktop) (Mac/Windows)
   - [Docker Engine](https://docs.docker.com/engine/install/) (Linux)

2. **Use docker-compose**: MongoDB is pre-configured in `docker-compose.yaml`
   ```bash
   # Start MongoDB (and other services)
   docker-compose up -d mongodb
   
   # Stop services
   docker-compose down
   ```

3. **Connection string**: Already configured in `docker-compose.yaml`
   ```yaml
   mongodb:
     image: mongo:7
     ports:
       - "27017:27017"
   ```

**Why we use it**: MongoDB provides flexible document storage for conversation history and LangGraph checkpoints.

**Note**: Available from Branch 03 onwards.

### üîç Qdrant (Vector Database)

**What it is**: Vector database for semantic search and RAG (Retrieval Augmented Generation).

**Setup**:
1. **Docker image**: Qdrant runs as a Docker container (included in `docker-compose.yaml`)
   ```bash
   # Start Qdrant
   docker-compose up -d qdrant
   ```

2. **Configuration** in `docker-compose.yaml`:
   ```yaml
   qdrant:
     image: qdrant/qdrant:latest
     ports:
       - "6333:6333"
     volumes:
       - qdrant_storage:/qdrant/storage
   ```

3. **Access**: 
   - API: `http://localhost:6333`
   - Dashboard: `http://localhost:6333/dashboard`

**Why we use it**: Qdrant enables semantic search over character knowledge, powering our RAG-based chat agents.

**Note**: Available from Branch 05 onwards.

### üê≥ Docker Quick Reference

**Start all services**:
```bash
docker-compose up -d
```

**Check running services**:
```bash
docker-compose ps
```

**View logs**:
```bash
docker-compose logs -f
```

**Stop all services**:
```bash
docker-compose down
```

**Clean up (remove volumes)**:
```bash
docker-compose down -v
```

---

## Configuration & environment

- Copy **`.env.example`** to **`.env`** and fill values for local dev (API keys, DB URLs, etc.).  
- Add a config loader (e.g., Pydantic `BaseSettings`) in `bootstrap/` to read `env` and/or `YAML` and construct adapters accordingly.

---

## Testing strategy (once code lands)

- **unit/**: domain models & use cases (replace outbound ports with fakes).  
- **integration/**: each adapter against a real sandbox (e.g., OpenAI test, local Qdrant).  
- **e2e/**: FastAPI routes calling real use cases with a test container stack.

---

## Conventions

- **Ports are framework‚Äëfree** (`Protocol`/ABC in `application/‚Ä¶_ports/`).  
- **Controllers call inbound ports.** Outbound adapters implement outbound ports.  
- **No service locator**: all wiring happens once in `bootstrap/` (constructor injection).  
- **Domain stays pure**: avoid importing infra/application from domain.

---

Happy building! Subsequent branches will add the first use case, a small FastAPI router, and a couple of outbound adapters (LLM + persistence) to demonstrate the full ports‚Äëand‚Äëadapters flow.


## Credits

This package was inspired by [Cookiecutter](https://github.com/audreyfeldroy/cookiecutter) and the [agent-api-cookiecutter](https://github.com/neural-maze/agent-api-cookiecutter) project template.
